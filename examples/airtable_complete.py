"""
Script complet pour scraper, organiser et extraire les donn√©es Airtable.

Ce script fait tout en une seule ex√©cution:
1. Scrape les donn√©es depuis une table Airtable partag√©e (format msgpack)
2. Parse et organise les donn√©es (colonnes, lignes)
3. Extrait les valeurs r√©elles en filtrant les m√©tadonn√©es
4. Fusionne les lignes avec le m√™me ID
5. Lie les donn√©es associ√©es (Batch, Current Program, etc.)
6. Sauvegarde dans un fichier JSON structur√©

Fonctionnalit√©s:
- D√©tection automatique des colonnes (fld...)
- Extraction intelligente des valeurs (filtrage des m√©tadonn√©es, URLs Airtable, etc.)
- Fusion des lignes dupliqu√©es avec le m√™me ID
- Liaison automatique des Batch aux lignes correspondantes via Current Program
- Mapping intelligent des valeurs (Website, Company Name, Description, etc.)

Usage:
    uv run examples/airtable_complete.py [URL_AIRTABLE] [--output OUTPUT_FILE]
    
Ou avec cookie pour les tables priv√©es:
    AIRTABLE_COOKIE="your_cookie" uv run examples/airtable_complete.py [URL_AIRTABLE]
    
Exemples:
    # Utiliser l'URL par d√©faut
    uv run examples/airtable_complete.py
    
    # Sp√©cifier une URL et un fichier de sortie
    uv run examples/airtable_complete.py "https://airtable.com/appXXX/shrXXX" --output data.json
    
    # Avec authentification
    AIRTABLE_COOKIE="session=..." uv run examples/airtable_complete.py
"""

import asyncio
import json
import os
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional

import httpx
from pydantic import BaseModel, Field

# Add the parent directory to the path so we can import browser_use
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from dotenv import load_dotenv

env_path = Path(project_root) / '.env'
if env_path.exists():
    load_dotenv(env_path)
else:
    load_dotenv()

try:
    import msgpack
except Exception:
    msgpack = None


# ============================================================================
# PARTIE 1: SCRAPING (r√©cup√©ration des donn√©es)
# ============================================================================

class AirtableRequestConfig(BaseModel):
    """Configuration pour la requ√™te Airtable."""
    base_url: str = "https://airtable.com/v0.3/view"
    view_id: str = "viw2BuXqXMTdAlSy8"
    share_id: str = "shrGtTkoHk6QOpsrT"
    application_id: str = "appfLUDj8A9RFqyxy"
    generation_number: int = 0
    expires: str = "2025-12-18T00:00:00.000Z"
    signature: str = "703b558f470297c2c349725d8eaf5b45e6fa8db7a4e539a36bb18f3c6fba2f97"
    should_use_nested_response_format: bool = True
    allow_msgpack_of_result: bool = True

    def build_access_policy(self) -> Dict[str, Any]:
        return {
            "allowedActions": [
                {"modelClassName": "view", "modelIdSelector": self.view_id, "action": "readSharedViewData"},
                {"modelClassName": "view", "modelIdSelector": self.view_id, "action": "getMetadataForPrinting"},
                {"modelClassName": "view", "modelIdSelector": self.view_id, "action": "readSignedAttachmentUrls"},
                {
                    "modelClassName": "row",
                    "modelIdSelector": f"rows *[displayedInView={self.view_id}]",
                    "action": "createDocumentPreviewSession",
                },
            ],
            "shareId": self.share_id,
            "applicationId": self.application_id,
            "generationNumber": self.generation_number,
            "expires": self.expires,
            "signature": self.signature,
        }

    def build_stringified_object_params(self) -> str:
        payload = {"shouldUseNestedResponseFormat": self.should_use_nested_response_format}
        if self.allow_msgpack_of_result:
            payload["allowMsgpackOfResult"] = True
        return json.dumps(payload, separators=(",", ":"))

    def build_query_params(self) -> Dict[str, str]:
        return {
            "stringifiedObjectParams": self.build_stringified_object_params(),
            "requestId": f"req{os.urandom(8).hex()[:16]}",
            "accessPolicy": json.dumps(self.build_access_policy(), separators=(",", ":")),
        }

    def build_url(self) -> str:
        query = httpx.QueryParams(self.build_query_params())
        return f"{self.base_url}/{self.view_id}/readSharedViewData?{query}"


def build_headers(config: AirtableRequestConfig, cookie: Optional[str]) -> Dict[str, str]:
    """Construit les headers pour la requ√™te."""
    headers = {
        "accept": "*/*",
        "accept-encoding": "gzip, deflate, br, zstd",
        "accept-language": "fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7",
        "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36",
        "x-airtable-application-id": config.application_id,
        "x-airtable-inter-service-client": "webClient",
        "x-airtable-page-load-id": "pglUhkf9b90Qk7b4l",
        "x-requested-with": "XMLHttpRequest",
        "x-time-zone": "Europe/Paris",
        "x-user-locale": "fr-FR",
    }
    if config.allow_msgpack_of_result:
        headers["x-airtable-accept-msgpack"] = "true"
    if cookie:
        headers["cookie"] = cookie
    return headers


def json_serialize(obj: Any) -> Any:
    """Helper pour s√©rialiser les objets non-JSON (bytes, etc.)."""
    if isinstance(obj, bytes):
        return obj.hex()
    if isinstance(obj, dict):
        return {k: json_serialize(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple)):
        return [json_serialize(item) for item in obj]
    return obj


def decode_response(response: httpx.Response) -> Dict[str, Any]:
    """D√©code la r√©ponse (JSON ou msgpack)."""
    content_type = response.headers.get("content-type", "")
    if "application/json" in content_type:
        try:
            return response.json()
        except Exception as e:
            return {"error": f"Failed to decode JSON: {e}", "raw_bytes": response.content.hex()}
    if "application/msgpack" in content_type and msgpack:
        try:
            try:
                return msgpack.unpackb(response.content, raw=False, strict_map_key=False)
            except msgpack.exceptions.ExtraData:
                unpacker = msgpack.Unpacker(raw=False, strict_map_key=False)
                unpacker.feed(response.content)
                results = []
                try:
                    while True:
                        results.append(unpacker.unpack())
                except msgpack.exceptions.OutOfData:
                    pass
                if results:
                    if len(results) == 1:
                        return results[0]
                    elif all(isinstance(r, dict) for r in results):
                        combined = {}
                        for r in results:
                            combined.update(r)
                        return combined
                    else:
                        return {"items": results}
                raise ValueError("No valid msgpack data found")
        except Exception as e:
            try:
                return response.json()
            except Exception:
                return {"error": f"Failed to decode msgpack: {e}", "raw_bytes": response.content.hex()[:1000]}
    try:
        return response.json()
    except Exception:
        return {"raw_bytes": response.content.hex(), "content_type": content_type}


def fetch_airtable_data(config: AirtableRequestConfig, cookie: Optional[str]) -> Dict[str, Any]:
    """R√©cup√®re les donn√©es depuis Airtable."""
    url = config.build_url()
    headers = build_headers(config, cookie)
    
    with httpx.Client(http2=False, headers=headers, follow_redirects=True) as client:
        response = client.get(url, timeout=30.0)
        response.raise_for_status()
        payload = decode_response(response)
        return {
            "url": url,
            "status_code": response.status_code,
            "content_type": response.headers.get("content-type"),
            "payload": payload,
        }


# ============================================================================
# PARTIE 2: EXTRACTION ET ORGANISATION
# ============================================================================

def extract_columns_direct(items: List[Any]) -> List[Dict[str, Any]]:
    """Extrait les colonnes en cherchant directement les patterns fld + nom + type."""
    columns = []
    i = 0
    
    while i < len(items):
        item = items[i]
        
        if isinstance(item, str) and item.startswith("fld"):
            fld_id = item
            col_data = {"id": fld_id}
            
            if i + 1 < len(items):
                next_item = items[i + 1]
                if isinstance(next_item, str) and not next_item.startswith(("fld", "rec", "tbl", "viw", "sel", "usr")):
                    col_data["name"] = next_item
                elif next_item is None:
                    if i + 2 < len(items) and isinstance(items[i + 2], str):
                        col_data["name"] = items[i + 2]
            
            # Types Airtable courants
            airtable_types = [
                "singleLineText", "multilineText", "email", "url", "phoneNumber",
                "number", "percent", "currency", "duration", "rating", "checkbox",
                "date", "dateTime", "multipleAttachments", "multipleRecordLinks",
                "singleSelect", "multipleSelects", "formula", "rollup", "count",
                "multipleAttachment", "foreignKey", "autoNumber", "barcode", "button",
                "createdTime", "lastModifiedTime", "createdBy", "lastModifiedBy",
            ]
            
            for j in range(i + 1, min(i + 10, len(items))):
                potential_type = items[j]
                if isinstance(potential_type, str) and potential_type in airtable_types:
                    col_data["type"] = potential_type
                    break
            
            if "name" in col_data or "type" in col_data:
                columns.append(col_data)
        
        i += 1
    
    return columns


def clean_value(value: Any) -> Any:
    """Nettoie une valeur pour la s√©rialisation JSON."""
    if value is None:
        return None
    if isinstance(value, bytes):
        return value.hex()
    if isinstance(value, dict):
        return {k: clean_value(v) for k, v in value.items()}
    if isinstance(value, (list, tuple)):
        return [clean_value(item) for item in value]
    return value


def is_value_item(item: Any) -> bool:
    """D√©termine si un item est une valeur de cellule (pas un ID ou m√©tadonn√©e)."""
    if item is None:
        return False
    if isinstance(item, str):
        # Ignorer les IDs
        if item.startswith(("rec", "fld", "tbl", "viw", "sel", "usr", "att")):
            return False
        # Ignorer les codes courts
        if len(item) < 3:
            return False
        return True
    if isinstance(item, (int, float, bool)):
        # Ignorer les codes/metadonn√©es (petits entiers)
        if isinstance(item, int) and item < 200:
            return False
        return True
    if isinstance(item, list):
        # Garder les listes avec des strings (s√©lections multiples)
        return any(isinstance(x, str) and not x.startswith(("rec", "fld")) for x in item)
    return False


def is_metadata_value(value: Any) -> bool:
    """D√©termine si une valeur est une m√©tadonn√©e √† ignorer (noms de fichiers, types MIME, dimensions, etc.)."""
    if not isinstance(value, str):
        return False
    
    # Types MIME
    if value.startswith("image/") or value.startswith("application/"):
        return True
    
    # Noms de fichiers avec extensions communes
    if any(value.endswith(ext) for ext in [".png", ".jpg", ".jpeg", ".svg", ".gif", ".pdf", ".webp"]):
        # Mais pas si c'est une URL compl√®te
        if not value.startswith("http"):
            return True
    
    # URLs de thumbnails Airtable
    if "airtable.com" in value and ("thumbnail" in value.lower() or "/.euc1/" in value):
        return True
    
    # Petits nombres (probablement des dimensions ou codes)
    if isinstance(value, (int, float)) and not isinstance(value, str) and value < 10000:
        return False  # On garde les nombres pour l'instant
    
    return False


def extract_rows_with_values(items: List[Any], columns: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Extrait les lignes avec leurs valeurs r√©elles en analysant la structure s√©rialis√©e.
    
    Pattern observ√© dans les donn√©es:
    - rec... (ID de ligne)
    - Industries (avec emoji) - Macro-Industries - Market
    - URL (Website) - si pas Airtable
    - [95] (code attachement)
    - att... (ID attachement)
    - URL logo (Company logo)
    - Nom fichier (√† ignorer)
    - "image/png" (type MIME - √† ignorer)
    - Nombre (taille - √† ignorer)
    - URLs thumbnails (√† ignorer)
    - Nombres (dimensions - √† ignorer)
    - [94] (code r√©f√©rence)
    - rec... (ID r√©f√©rence Current Program)
    - "Incubateur..." (Current Program)
    - [94] (code r√©f√©rence)
    - rec... (ID r√©f√©rence Batch)
    - "[Batch]..." (Batch)
    - [94] (code r√©f√©rence)
    - rec... (ID r√©f√©rence Industries Product)
    - Industries (avec emoji) - Macro-Industries - Product
    - Description (long texte)
    - Company Name (court texte)
    - 92 (code)
    - rec... (ID ligne suivante ou r√©f√©rence)
    - createdTime (date ISO)
    - 93 (code)
    - [sel...] (s√©lection)
    """
    rows = []
    
    # Trouver toutes les positions des lignes principales (rec... qui sont des IDs de lignes)
    # On identifie les lignes principales en cherchant des patterns sp√©cifiques
    row_positions = []
    i = 0
    while i < len(items):
        item = items[i]
        
        # Un ID de ligne principal est suivi g√©n√©ralement par des Industries (avec emoji)
        if isinstance(item, str) and item.startswith("rec") and len(item) > 10:
            # V√©rifier si c'est suivi d'une valeur int√©ressante (pas juste une r√©f√©rence)
            # Regarder les 5 prochains items
            is_main_row = False
            for j in range(i + 1, min(i + 6, len(items))):
                next_item = items[j]
                # Si on trouve une Industries avec emoji, une URL, ou une description, c'est une ligne principale
                if isinstance(next_item, str):
                    # Industries avec emoji
                    if len(next_item) > 5 and any(ord(c) > 127 for c in next_item[:5]):
                        is_main_row = True
                        break
                    # URL (pas Airtable)
                    if next_item.startswith("http") and "airtable.com" not in next_item:
                        is_main_row = True
                        break
                    # Description longue
                    if len(next_item) > 50 and not next_item.startswith("http"):
                        is_main_row = True
                        break
            
            if is_main_row:
                row_positions.append(i)
        
        i += 1
    
    # Pour chaque ligne principale, extraire les valeurs
    for idx, pos in enumerate(row_positions):
        row_id = items[pos]
        row_data = {"id": row_id}
        
        # Trouver la position de la prochaine ligne principale
        next_pos = row_positions[idx + 1] if idx + 1 < len(row_positions) else min(pos + 100, len(items))
        
        # Extraire les valeurs mais s'arr√™ter quand on d√©tecte une nouvelle entreprise
        values = []
        i = pos + 1
        found_company_name = False
        found_description = False
        found_website = False
        found_created_time = False
        
        while i < next_pos:
            item = items[i]
            
            # D√©tecter les patterns de fin de bloc [0, "00"] - marqueur de fin d'entreprise
            # V√©rifier AVANT d'extraire les valeurs pour √©viter de m√©langer les entreprises
            if isinstance(item, list) and len(item) == 2 and item[0] == 0 and item[1] == "00":
                # Si on a d√©j√† extrait les donn√©es principales, v√©rifier s'il y a une nouvelle entreprise apr√®s
                if found_company_name or found_description or found_website:
                    # V√©rifier les 5 prochains items pour voir s'il y a une nouvelle entreprise
                    has_new_company = False
                    for j in range(i + 1, min(i + 6, len(items))):
                        next_item = items[j]
                        # Ignorer les codes et m√©tadonn√©es
                        if isinstance(next_item, int) and next_item < 200:
                            continue
                        if isinstance(next_item, list):
                            continue
                        if isinstance(next_item, str):
                            # URL (pas Airtable) = nouvelle entreprise
                            if next_item.startswith("http") and "airtable.com" not in next_item:
                                has_new_company = True
                                break
                            if next_item.startswith("www."):
                                has_new_company = True
                                break
                            # Description longue = nouvelle entreprise
                            if len(next_item) > 50 and not next_item.startswith("http"):
                                has_new_company = True
                                break
                            # Nom d'entreprise court = nouvelle entreprise
                            if 3 < len(next_item) < 60 and not any(ord(c) > 127 for c in next_item[:3]):
                                if not next_item.startswith("http") and ";" not in next_item:
                                    has_new_company = True
                                    break
                    
                    # Si on a trouv√© une nouvelle entreprise apr√®s [0, "00"], s'arr√™ter IMM√âDIATEMENT
                    # Le pattern [0, "00"] marque la fin de l'entreprise actuelle
                    # Ne pas extraire les valeurs qui suivent
                    if has_new_company:
                        # S'arr√™ter ici, ne pas continuer l'extraction
                        break
                    # Si on a trouv√© createdTime, on peut aussi s'arr√™ter apr√®s [0, "00"]
                    elif found_created_time:
                        break
                # Si on a d√©tect√© [0, "00"], continuer sans extraire cette valeur
                i += 1
                continue
            
            # Ignorer les codes/metadonn√©es
            if isinstance(item, int) and item < 200:
                i += 1
                continue
            
            # Ignorer les listes de r√©f√©rences simples [94], [95]
            if isinstance(item, list) and len(item) == 1 and isinstance(item[0], int):
                i += 1
                continue
            
            # D√©tecter si on a trouv√© une nouvelle entreprise (pattern: rec... suivi d'Industries/URL/Description)
            if isinstance(item, str) and item.startswith("rec") and len(item) > 10:
                # V√©rifier si c'est le d√©but d'une nouvelle entreprise
                # Regarder les 3 prochains items pour voir si c'est un pattern d'entreprise
                is_new_company = False
                for j in range(i + 1, min(i + 4, len(items))):
                    next_item = items[j]
                    if isinstance(next_item, str):
                        # Industries avec emoji
                        if len(next_item) > 5 and any(ord(c) > 127 for c in next_item[:5]) and ";" in next_item:
                            is_new_company = True
                            break
                        # URL (pas Airtable)
                        if next_item.startswith("http") and "airtable.com" not in next_item:
                            is_new_company = True
                            break
                        if next_item.startswith("www."):
                            is_new_company = True
                            break
                        # Description longue
                        if len(next_item) > 50 and not next_item.startswith("http"):
                            is_new_company = True
                            break
                
                # Si c'est une nouvelle entreprise et qu'on a d√©j√† extrait les donn√©es principales, s'arr√™ter
                if is_new_company and (found_company_name or found_description or found_website):
                    break
            
            # Ignorer les IDs de r√©f√©rences (rec, att, sel, etc.) sauf si on les utilise
            if isinstance(item, str):
                if item.startswith(("rec", "att", "sel", "fld", "tbl", "viw", "usr")) and len(item) > 10:
                    # On garde les rec... qui peuvent √™tre des r√©f√©rences √† d'autres tables
                    # Mais on va les utiliser pour mapper les valeurs suivantes
                    pass
                elif not is_metadata_value(item):
                    # AVANT d'extraire, v√©rifier si on vient de passer un [0, "00"] et si c'est une nouvelle entreprise
                    # V√©rifier les 3 items pr√©c√©dents pour voir s'il y a un [0, "00"]
                    just_after_end_marker = False
                    for k in range(max(0, i - 3), i):
                        prev_item = items[k]
                        if isinstance(prev_item, list) and len(prev_item) == 2 and prev_item[0] == 0 and prev_item[1] == "00":
                            # On vient de passer un [0, "00"], v√©rifier si cette valeur est une nouvelle entreprise
                            if isinstance(item, str):
                                if (item.startswith("www.") or 
                                    (item.startswith("http") and "airtable.com" not in item) or
                                    (len(item) > 50 and not item.startswith("http")) or
                                    (3 < len(item) < 60 and not any(ord(c) > 127 for c in item[:3]) and ";" not in item)):
                                    # C'est probablement une nouvelle entreprise, ne pas l'extraire
                                    just_after_end_marker = True
                                    break
                    
                    if just_after_end_marker:
                        # Ne pas extraire cette valeur, c'est une nouvelle entreprise
                        i += 1
                        continue
                    
                    # C'est une valeur int√©ressante
                    cleaned = clean_value(item)
                    if cleaned and isinstance(cleaned, str) and cleaned.strip():
                        values.append((i, cleaned))
                        # Marquer qu'on a trouv√© des donn√©es principales
                        if len(cleaned) > 50 and not cleaned.startswith("http"):
                            found_description = True
                        elif cleaned.startswith("http") and "airtable.com" not in cleaned:
                            found_website = True
                        elif cleaned.startswith("www."):
                            found_website = True
                        elif 3 < len(cleaned) < 60 and not any(ord(c) > 127 for c in cleaned[:3]):
                            if not cleaned.startswith("http") and ";" not in cleaned:
                                found_company_name = True
                        # D√©tecter createdTime (date ISO)
                        elif "T" in cleaned and cleaned.count("-") >= 2 and cleaned.count(":") >= 2:
                            try:
                                from datetime import datetime
                                datetime.fromisoformat(cleaned.replace("Z", "+00:00"))
                                found_created_time = True
                            except:
                                pass
            
            i += 1
        
        # Filtrer les valeurs qui ont √©t√© extraites apr√®s un [0, "00"] (nouvelles entreprises)
        # Trouver toutes les positions de [0, "00"] dans la plage d'extraction
        end_marker_positions = []
        for k in range(pos, min(next_pos, len(items))):
            item = items[k]
            if isinstance(item, list) and len(item) == 2 and item[0] == 0 and item[1] == "00":
                end_marker_positions.append(k)
        
        # Trouver le dernier [0, "00"] qui est suivi d'une nouvelle entreprise
        # et apr√®s lequel on a d√©j√† extrait des donn√©es principales
        cutoff_position = next_pos  # Par d√©faut, garder toutes les valeurs
        
        for end_pos in reversed(end_marker_positions):  # Commencer par le dernier
            # V√©rifier si on a d√©j√† extrait des donn√©es avant ce [0, "00"]
            has_data_before = False
            for pos_val, value in values:
                if pos_val < end_pos:
                    has_data_before = True
                    break
            
            if has_data_before:
                # V√©rifier s'il y a une nouvelle entreprise apr√®s ce [0, "00"]
                for j in range(end_pos + 1, min(end_pos + 10, len(items))):
                    next_item = items[j]
                    # Ignorer les codes et m√©tadonn√©es
                    if isinstance(next_item, int) and next_item < 200:
                        continue
                    if isinstance(next_item, list):
                        continue
                    if isinstance(next_item, str):
                        if (next_item.startswith("www.") or 
                            (next_item.startswith("http") and "airtable.com" not in next_item and "airtableusercontent.com" not in next_item) or
                            (len(next_item) > 50 and not next_item.startswith("http")) or
                            (3 < len(next_item) < 60 and not any(ord(c) > 127 for c in next_item[:3]) and ";" not in next_item)):
                            # Nouvelle entreprise d√©tect√©e apr√®s ce [0, "00"]
                            cutoff_position = end_pos
                            break
                if cutoff_position < next_pos:
                    break
        
        # Filtrer les valeurs qui viennent apr√®s le cutoff
        filtered_values = [(pos_val, value) for pos_val, value in values if pos_val <= cutoff_position]
        
        # Utiliser les valeurs filtr√©es
        values = filtered_values
        
        # Maintenant, mapper les valeurs intelligemment
        # On va chercher les patterns dans l'ordre observ√©
        
        # 1. Industries - Market (premier texte avec emoji, g√©n√©ralement au d√©but)
        for pos_val, value in values:
            if isinstance(value, str) and len(value) > 5:
                # V√©rifier si c'est une Industries avec emoji
                if any(ord(c) > 127 for c in value[:5]) and ";" in value:
                    row_data["Macro-Industries - Market"] = value
                    break
        
        # 2. Website (URL qui n'est pas Airtable)
        # V√©rifier que le Website correspond √† l'entreprise (pas une autre entreprise)
        for pos_val, value in values:
            if isinstance(value, str) and value.startswith("http") and "airtable.com" not in value:
                # Ignorer les URLs Airtable m√™me si "airtable.com" n'est pas dans le domaine
                if "airtableusercontent.com" in value or "v5.airtable" in value:
                    continue
                # V√©rifier que cette URL ne vient pas apr√®s un [0, "00"] (nouvelle entreprise)
                comes_after_end_marker = False
                for k in range(pos_val - 1, max(pos_val - 15, pos), -1):
                    if k < len(items) and k >= pos:
                        prev_item = items[k]
                        if isinstance(prev_item, list) and len(prev_item) == 2 and prev_item[0] == 0 and prev_item[1] == "00":
                            # V√©rifier s'il y a une nouvelle entreprise apr√®s ce [0, "00"]
                            for j in range(k + 1, min(k + 6, len(items))):
                                next_item = items[j]
                                if isinstance(next_item, str):
                                    if (next_item.startswith("www.") or 
                                        (next_item.startswith("http") and "airtable.com" not in next_item) or
                                        (len(next_item) > 50 and not next_item.startswith("http"))):
                                        comes_after_end_marker = True
                                        break
                            if comes_after_end_marker:
                                break
                if comes_after_end_marker and (found_company_name or found_description):
                    # Cette URL vient apr√®s un [0, "00"] suivi d'une nouvelle entreprise, ne pas l'utiliser
                    continue
                row_data["Website"] = value
                break
            # Aussi accepter les URLs qui commencent par www.
            elif isinstance(value, str) and value.startswith("www.") and "airtable.com" not in value:
                # V√©rifier que cette URL ne vient pas apr√®s un [0, "00"]
                comes_after_end_marker = False
                for k in range(pos_val - 1, max(pos_val - 15, pos), -1):
                    if k < len(items) and k >= pos:
                        prev_item = items[k]
                        if isinstance(prev_item, list) and len(prev_item) == 2 and prev_item[0] == 0 and prev_item[1] == "00":
                            # V√©rifier s'il y a une nouvelle entreprise apr√®s ce [0, "00"]
                            for j in range(k + 1, min(k + 6, len(items))):
                                next_item = items[j]
                                if isinstance(next_item, str):
                                    if (next_item.startswith("www.") or 
                                        (next_item.startswith("http") and "airtable.com" not in next_item) or
                                        (len(next_item) > 50 and not next_item.startswith("http"))):
                                        comes_after_end_marker = True
                                        break
                            if comes_after_end_marker:
                                break
                if comes_after_end_marker and (found_company_name or found_description):
                    # Cette URL vient apr√®s un [0, "00"] suivi d'une nouvelle entreprise, ne pas l'utiliser
                    continue
                row_data["Website"] = f"https://{value}"
                break
        
        # 3. Company logo (URL Airtable directUploadAttachment)
        for pos_val, value in values:
            if isinstance(value, str) and "airtable.com" in value and "directUploadAttachment" in value:
                row_data["Company logo"] = value
                break
        
        # 4. Current Program (texte contenant "Incubateur", "CDL", "Program", "Station", etc.)
        for pos_val, value in values:
            if isinstance(value, str) and any(keyword in value for keyword in [
                "Incubateur", "CDL", "Program", "Station", "Online", "TotalEnergies", "Akwa"
            ]) and "[" not in value:  # Pas un Batch
                row_data["Current Program"] = value
                break
        
        # 5. Batch (texte avec [] ou contenant "Batch")
        for pos_val, value in values:
            if isinstance(value, str) and ("[" in value and "]" in value or "Batch" in value):
                row_data["Batch"] = value
                break
        
        # 6. Industries - Product (deuxi√®me texte avec emoji, g√©n√©ralement apr√®s Batch)
        industries_found = 0
        for pos_val, value in values:
            if isinstance(value, str) and len(value) > 5:
                if any(ord(c) > 127 for c in value[:5]) and ";" in value:
                    industries_found += 1
                    if industries_found == 2:  # La deuxi√®me Industries
                        row_data["Macro-Industries - Product"] = value
                        break
        
        # 7. Description EN (texte long, g√©n√©ralement apr√®s Industries)
        for pos_val, value in values:
            if isinstance(value, str) and len(value) > 80:
                # V√©rifier que ce n'est pas une URL ou autre
                if not value.startswith("http") and "Description EN" not in row_data:
                    # V√©rifier que √ßa ressemble √† une description (contient des mots communs)
                    if any(word in value.lower() for word in ["the", "is", "are", "and", "for", "with", "that", "this"]):
                        row_data["Description EN"] = value
                        break
        
        # 8. Company Name (texte court, g√©n√©ralement apr√®s la description, pas d'emoji, pas une description)
        # Chercher apr√®s la description si elle existe
        search_start = 0
        for pos_val, value in values:
            if value == row_data.get("Description EN"):
                # Trouver la position de la description et chercher apr√®s
                for idx, (p, v) in enumerate(values):
                    if v == value:
                        search_start = idx + 1
                        break
                break
        
        for pos_val, value in values[search_start:]:
            if isinstance(value, str) and 3 < len(value) < 60:
                # Ignorer les dates
                if "T" in value and value.count("-") >= 2 and value.count(":") >= 2:
                    continue
                
                # Ignorer les URLs
                if value.startswith("http") or value.startswith("www."):
                    continue
                
                # Ignorer les noms de fichiers (extensions communes)
                if any(value.lower().endswith(ext) for ext in [".png", ".jpg", ".jpeg", ".svg", ".gif", ".pdf", ".webp", ".jpeg"]):
                    continue
                
                # Ignorer les noms contenant "logo", "Logo", "image", etc.
                if any(word in value.lower() for word in ["logo", "image", "copy", "jpg", "png", "svg"]):
                    continue
                
                # Pas d'emoji au d√©but
                if any(ord(c) > 127 for c in value[:3]):
                    continue
                
                # Pas une description (pas de mots comme "the", "is", etc. au d√©but)
                first_words = value.split()[:3]
                if any(word.lower() in ["the", "is", "are", "and", "for", "with", "that", "this", "we", "our"] 
                      for word in first_words):
                    continue
                
                # Pas d√©j√† mapp√©
                if value not in row_data.values():
                    row_data["Company Name"] = value
                    break
        
        # 9. createdTime (date ISO)
        for pos_val, value in values:
            if isinstance(value, str) and "T" in value and value.count("-") >= 2 and value.count(":") >= 2:
                try:
                    # V√©rifier que c'est une date valide
                    from datetime import datetime
                    datetime.fromisoformat(value.replace("Z", "+00:00"))
                    row_data["createdTime"] = value
                    found_created_time = True
                    break
                except:
                    pass
        
        # Nettoyage final : v√©rifier la coh√©rence entre Company Name et Website
        # Si le Website ne correspond pas au Company Name, le supprimer
        company_name = row_data.get("Company Name", "").lower()
        website = row_data.get("Website", "").lower()
        
        if website:
            # Trouver la position du website dans les items
            website_pos = None
            for pos_val, value in values:
                value_str = str(value).lower()
                if value_str == website or value_str == website.replace("https://", "").replace("http://", "").replace("www.", ""):
                    website_pos = pos_val
                    break
            
            # Si on a trouv√© la position, v√©rifier si elle vient apr√®s un [0, "00"]
            if website_pos:
                comes_after_end_marker = False
                for k in range(website_pos - 1, max(website_pos - 15, pos), -1):
                    if k < len(items) and k >= pos:
                        prev_item = items[k]
                        if isinstance(prev_item, list) and len(prev_item) == 2 and prev_item[0] == 0 and prev_item[1] == "00":
                            comes_after_end_marker = True
                            break
                
                if comes_after_end_marker and (found_company_name or found_description):
                    # Ce website vient apr√®s un [0, "00"], c'est une autre entreprise
                    if "Website" in row_data:
                        del row_data["Website"]
                
                # V√©rifier aussi la coh√©rence avec le Company Name
                elif company_name:
                    website_domain = website.replace("https://", "").replace("http://", "").replace("www.", "").split("/")[0]
                    company_keywords = [w for w in company_name.split() if len(w) > 3]
                    # Si le domaine ne contient aucun mot-cl√© du company name, c'est suspect
                    if company_keywords and not any(kw in website_domain for kw in company_keywords):
                        # V√©rifier si c'est vraiment le website de cette entreprise
                        if comes_after_end_marker or (website_pos and website_pos > pos + 20):
                            # Ce website est trop loin ou vient apr√®s un marqueur, c'est suspect
                            if "Website" in row_data:
                                del row_data["Website"]
        
        # Ajouter toutes les valeurs brutes pour r√©f√©rence (limit√©es)
        # Utiliser les valeurs filtr√©es (d√©j√† filtr√©es plus haut)
        all_raw = [v for _, v in values[:30]]  # Limiter √† 30 valeurs
        if all_raw:
            row_data["_all_values"] = all_raw
        
        rows.append(row_data)
    
    return rows


def deduplicate_rows(rows: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    D√©duplique les lignes en se basant sur Company Name + Website plut√¥t que sur l'ID.
    Les m√™mes IDs peuvent repr√©senter des entreprises diff√©rentes dans le flux s√©rialis√©.
    """
    seen = set()
    unique_rows = []
    
    for row in rows:
        # Cr√©er une cl√© unique bas√©e sur Company Name et Website
        company_name = row.get("Company Name", "").strip()
        website = row.get("Website", "").strip()
        
        # Si on a un Company Name, l'utiliser comme cl√© principale
        if company_name:
            key = f"name:{company_name}"
        # Sinon, utiliser Website
        elif website:
            key = f"website:{website}"
        # Sinon, utiliser Description comme fallback
        elif row.get("Description EN"):
            desc = str(row.get("Description EN", ""))[:50].strip()
            key = f"desc:{desc}"
        # Dernier recours : utiliser l'ID + un hash des valeurs
        else:
            values_str = str(sorted(row.items()))[:100]
            key = f"id:{row.get('id', 'unknown')}:{hash(values_str)}"
        
        # Si cette cl√© n'a pas √©t√© vue, ajouter la ligne
        if key not in seen:
            seen.add(key)
            # Cr√©er un ID unique pour cette ligne (bas√© sur l'index)
            row["_unique_id"] = f"row_{len(unique_rows)}"
            unique_rows.append(row)
        else:
            # Si on a d√©j√† vu cette cl√©, on peut fusionner seulement si les donn√©es sont compl√©mentaires
            # Pour l'instant, on ignore les doublons
            pass
    
    return unique_rows


def link_related_data(rows: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Lie les donn√©es associ√©es (comme Batch qui correspond √† Current Program).
    Regroupe les lignes qui partagent des r√©f√©rences communes.
    """
    # Cr√©er un index des lignes par Current Program
    program_to_rows = {}
    batch_rows = []  # Lignes qui ont seulement un Batch
    
    # Premi√®re passe : indexer par Current Program et identifier les lignes Batch
    for row in rows:
        program = row.get("Current Program")
        batch = row.get("Batch")
        
        # Si la ligne a un Current Program, l'indexer
        if program:
            if program not in program_to_rows:
                program_to_rows[program] = []
            program_to_rows[program].append(row)
        
        # Si la ligne a seulement un Batch (pas d'autres donn√©es importantes), la marquer
        if batch and not program and not row.get("Website") and not row.get("Company Name") and not row.get("Description EN"):
            batch_rows.append(row)
    
    # Deuxi√®me passe : lier les Batch aux lignes avec Current Program correspondant
    merged_rows = {}
    batch_ids_to_remove = set()
    
    # D'abord, copier toutes les lignes principales
    for row in rows:
        row_id = row.get("id")
        if row_id:
            merged_rows[row_id] = row.copy()
    
    # Ensuite, lier les Batch
    for batch_row in batch_rows:
        batch = batch_row.get("Batch")
        if not batch:
            continue
        
        # Extraire le nom du programme depuis le Batch (format: "[Program] ...")
        program_name = None
        if "[" in batch and "]" in batch:
            program_name = batch.split("]")[0].replace("[", "").strip()
        
        if program_name:
            # Chercher une ligne avec ce Current Program
            found_match = False
            for linked_row in program_to_rows.get(program_name, []):
                linked_id = linked_row.get("id")
                if linked_id and linked_id in merged_rows:
                    # Fusionner le Batch dans la ligne correspondante
                    if "Batch" not in merged_rows[linked_id] or not merged_rows[linked_id]["Batch"]:
                        merged_rows[linked_id]["Batch"] = batch
                    found_match = True
                    break
            
            # Si on a trouv√© une correspondance, marquer cette ligne Batch pour suppression
            if found_match:
                batch_ids_to_remove.add(batch_row.get("id"))
    
    # Retourner les lignes fusionn√©es (sans les Batch isol√©s qui ont √©t√© li√©s)
    result = []
    for row_id, row in merged_rows.items():
        if row_id not in batch_ids_to_remove:
            result.append(row)
    
    return result


def organize_data(data: Dict[str, Any]) -> Dict[str, Any]:
    """Organise les donn√©es scrap√©es avec les valeurs r√©elles."""
    payload = data.get("payload", {})
    
    # Si le payload contient "items", utiliser directement
    if "items" in payload:
        items = payload["items"]
    elif isinstance(payload, dict) and "error" not in payload:
        # Essayer de trouver items ailleurs
        items = payload.get("data", {}).get("items", [])
        if not items:
            items = []
    else:
        items = []
    
    if not items:
        return {
            "error": "No items found in payload",
            "payload_keys": list(payload.keys()) if isinstance(payload, dict) else [],
        }
    
    # Extraire colonnes d'abord
    columns = extract_columns_direct(items)
    
    # Extraire les lignes avec leurs valeurs r√©elles
    rows = extract_rows_with_values(items, columns)
    
    # D√©dupliquer les lignes bas√© sur Company Name/Website plut√¥t que sur ID
    # (les m√™mes IDs peuvent repr√©senter des entreprises diff√©rentes)
    rows = deduplicate_rows(rows)
    
    # Lier les donn√©es associ√©es (Batch, etc.)
    rows = link_related_data(rows)
    
    # Cr√©er le mapping colonne ID -> nom
    column_mapping = {col["id"]: col.get("name") or col["id"] for col in columns}
    
    return {
        "metadata": {
            "source_url": data.get("url", ""),
            "status_code": data.get("status_code", 0),
            "content_type": data.get("content_type", ""),
            "total_items": len(items),
        },
        "columns": columns,
        "rows": rows,  # Maintenant avec les valeurs r√©elles
        "column_mapping": column_mapping,
        "statistics": {
            "total_columns": len(columns),
            "total_rows": len(rows),
        },
    }


# ============================================================================
# PARTIE 3: FONCTION PRINCIPALE
# ============================================================================

def extract_params_from_url(url: str) -> Optional[Dict[str, str]]:
    """Extrait les param√®tres depuis l'URL Airtable."""
    try:
        # Format: https://airtable.com/appXXX/shrXXX/tblXXX?viewControls=on
        # ou: https://airtable.com/shrXXX
        parts = url.replace("https://airtable.com/", "").split("/")
        
        params = {}
        if len(parts) >= 1:
            if parts[0].startswith("app"):
                params["application_id"] = parts[0]
            if len(parts) >= 2 and parts[1].startswith("shr"):
                params["share_id"] = parts[1]
            if len(parts) >= 3 and parts[2].startswith("tbl"):
                params["table_id"] = parts[2]
        
        # Extraire view_id depuis les query params si pr√©sent
        if "?" in url:
            query_part = url.split("?")[1]
            if "view=" in query_part:
                view_part = query_part.split("view=")[1].split("&")[0]
                if view_part.startswith("viw"):
                    params["view_id"] = view_part
        
        return params if params else None
    except Exception:
        return None


def main():
    """Fonction principale compl√®te."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Scrape, organize and extract Airtable data")
    parser.add_argument("url", nargs="?", help="Airtable shared view URL")
    parser.add_argument("--output", "-o", default="airtable_extracted.json", help="Output file path")
    parser.add_argument("--cookie", help="Cookie header for authentication (or use AIRTABLE_COOKIE env var)")
    
    args = parser.parse_args()
    
    # URL par d√©faut ou depuis les arguments
    table_url = args.url or "https://airtable.com/appfLUDj8A9RFqyxy/shrGtTkoHk6QOpsrT/tbluZLSM3l4mENfIk?viewControls=on"
    
    # Cookie depuis argument ou variable d'environnement
    cookie = args.cookie or os.getenv("AIRTABLE_COOKIE")
    
    print("=" * 70)
    print("üîç Airtable Complete Scraper & Organizer")
    print("=" * 70)
    print(f"URL: {table_url}")
    print()
    
    # √âtape 1: Scraping
    print("üì• √âTAPE 1: Scraping des donn√©es depuis Airtable...")
    try:
        config = AirtableRequestConfig()
        
        # Essayer d'extraire les param√®tres depuis l'URL
        url_params = extract_params_from_url(table_url)
        if url_params:
            if "application_id" in url_params:
                config.application_id = url_params["application_id"]
            if "share_id" in url_params:
                config.share_id = url_params["share_id"]
            if "view_id" in url_params:
                config.view_id = url_params["view_id"]
        
        raw_data = fetch_airtable_data(config, cookie)
        
        if raw_data.get("status_code") != 200:
            print(f"‚ùå Erreur: Status {raw_data.get('status_code')}")
            return
        
        print(f"‚úÖ Donn√©es r√©cup√©r√©es (Status: {raw_data.get('status_code')})")
        print(f"   Content-Type: {raw_data.get('content_type', 'N/A')}")
        
    except Exception as e:
        print(f"‚ùå Erreur lors du scraping: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # √âtape 2: Organisation
    print("\nüìä √âTAPE 2: Organisation et extraction des donn√©es...")
    try:
        organized = organize_data(raw_data)
        
        if "error" in organized:
            print(f"‚ùå Erreur: {organized['error']}")
            return
        
        stats = organized.get("statistics", {})
        rows = organized.get("rows", [])
        columns = organized.get("columns", [])
        
        print(f"‚úÖ Donn√©es organis√©es:")
        print(f"   - Colonnes: {stats.get('total_columns', 0)}")
        print(f"   - Lignes: {stats.get('total_rows', 0)}")
        
        # Statistiques d√©taill√©es
        if rows:
            rows_with_website = sum(1 for r in rows if r.get("Website"))
            rows_with_name = sum(1 for r in rows if r.get("Company Name"))
            rows_with_desc = sum(1 for r in rows if r.get("Description EN"))
            rows_with_program = sum(1 for r in rows if r.get("Current Program"))
            rows_with_batch = sum(1 for r in rows if r.get("Batch"))
            rows_complete = sum(1 for r in rows if r.get("Website") and r.get("Company Name") and (r.get("Description EN") or r.get("Current Program")))
            
            print(f"\nüìä Statistiques d'extraction:")
            print(f"   - Lignes avec Website: {rows_with_website}")
            print(f"   - Lignes avec Company Name: {rows_with_name}")
            print(f"   - Lignes avec Description: {rows_with_desc}")
            print(f"   - Lignes avec Current Program: {rows_with_program}")
            print(f"   - Lignes avec Batch: {rows_with_batch}")
            print(f"   - Lignes compl√®tes: {rows_complete}")
        
        # Afficher les colonnes
        if columns:
            print(f"\nüìã Colonnes trouv√©es ({len(columns)}):")
            for col in columns[:15]:
                name = col.get("name") or "N/A"
                col_type = col.get("type") or "N/A"
                col_id = col.get("id") or "N/A"
                print(f"   - {str(name):40s} ({col_id}) - {col_type}")
            if len(columns) > 15:
                print(f"   ... et {len(columns) - 15} autres colonnes")
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'organisation: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # √âtape 3: Sauvegarde
    print(f"\nüíæ √âTAPE 3: Sauvegarde dans {args.output}...")
    try:
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(organized, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ Fichier sauvegard√©: {output_path.absolute()}")
        print(f"   Taille: {output_path.stat().st_size / 1024:.1f} KB")
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la sauvegarde: {e}")
        import traceback
        traceback.print_exc()
        return
    
    print("\n" + "=" * 70)
    print("‚úÖ Processus termin√© avec succ√®s!")
    print("=" * 70)


if __name__ == "__main__":
    main()

